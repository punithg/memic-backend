"""add_rag_file_models

Revision ID: 90c7d541ca8d
Revises: f17611bea07c
Create Date: 2025-10-20 23:20:50.135805

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '90c7d541ca8d'
down_revision: Union[str, None] = 'f17611bea07c'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('files',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('original_filename', sa.String(length=500), nullable=False),
    sa.Column('size', sa.Integer(), nullable=False),
    sa.Column('mime_type', sa.String(length=100), nullable=False),
    sa.Column('project_id', sa.UUID(), nullable=False),
    sa.Column('uploaded_by_user_id', sa.UUID(), nullable=False),
    sa.Column('status', sa.Enum('UPLOADING', 'UPLOADED', 'UPLOAD_FAILED', 'CONVERSION_STARTED', 'CONVERSION_COMPLETE', 'CONVERSION_FAILED', 'PARSING_STARTED', 'PARSING_COMPLETE', 'PARSING_FAILED', 'CHUNKING_STARTED', 'CHUNKING_COMPLETE', 'CHUNKING_FAILED', 'EMBEDDING_STARTED', 'EMBEDDING_COMPLETE', 'EMBEDDING_FAILED', 'READY', name='file_status_enum'), nullable=False),
    sa.Column('blob_storage_path', sa.String(length=1000), nullable=False),
    sa.Column('is_converted', sa.Boolean(), nullable=False),
    sa.Column('converted_file_path', sa.String(length=1000), nullable=True),
    sa.Column('enriched_file_path', sa.String(length=1000), nullable=True),
    sa.Column('total_chunks', sa.Integer(), nullable=False),
    sa.Column('conversion_started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('conversion_completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('parsing_started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('parsing_completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('chunking_started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('chunking_completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('embedding_started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('embedding_completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['uploaded_by_user_id'], ['users.id'], ondelete='RESTRICT'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_files_created_at', 'files', ['created_at'], unique=False)
    op.create_index('idx_files_project_id', 'files', ['project_id'], unique=False)
    op.create_index('idx_files_status', 'files', ['status'], unique=False)
    op.create_index('idx_files_uploaded_by_user_id', 'files', ['uploaded_by_user_id'], unique=False)
    op.create_table('file_chunks',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('file_id', sa.UUID(), nullable=False),
    sa.Column('chunk_index', sa.Integer(), nullable=False),
    sa.Column('chunk_text', sa.Text(), nullable=False),
    sa.Column('token_count', sa.Integer(), nullable=False),
    sa.Column('blob_storage_path', sa.String(length=1000), nullable=True),
    sa.Column('vector_id', sa.String(length=255), nullable=True),
    sa.Column('chunk_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['file_id'], ['files.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_file_chunks_chunk_index', 'file_chunks', ['chunk_index'], unique=False)
    op.create_index('idx_file_chunks_file_id', 'file_chunks', ['file_id'], unique=False)
    op.create_index('idx_file_chunks_vector_id', 'file_chunks', ['vector_id'], unique=False)
    op.create_table('file_metadata',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('file_id', sa.UUID(), nullable=False),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['file_id'], ['files.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_file_metadata_file_id', 'file_metadata', ['file_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('idx_file_metadata_file_id', table_name='file_metadata')
    op.drop_table('file_metadata')
    op.drop_index('idx_file_chunks_vector_id', table_name='file_chunks')
    op.drop_index('idx_file_chunks_file_id', table_name='file_chunks')
    op.drop_index('idx_file_chunks_chunk_index', table_name='file_chunks')
    op.drop_table('file_chunks')
    op.drop_index('idx_files_uploaded_by_user_id', table_name='files')
    op.drop_index('idx_files_status', table_name='files')
    op.drop_index('idx_files_project_id', table_name='files')
    op.drop_index('idx_files_created_at', table_name='files')
    op.drop_table('files')
    # ### end Alembic commands ###
